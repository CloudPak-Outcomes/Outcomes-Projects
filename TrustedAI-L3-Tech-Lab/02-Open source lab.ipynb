{"cells": [{"metadata": {}, "cell_type": "markdown", "source": "# 1. Insert project token, API key, and region\n\nClick the **three vertical dots** icon above and select **Insert project token** to provide this notebook API access to your project. The code inserted above will have a line that looks like this:\n\n`project = Project(project_id='xxxxxxxx-xxx-xxxx-xxxx-xxxxxxxxxx', project_access_token='p-xxxxxxxxxxxxxxxxxx')`\n\nThat `project_id` value should be pasted into the cell below as the value for `PROJECT_ID`. The API key you created earlier in the lab should be pasted into the cell as the value for `API_KEY`. The region your account is in (such as `us-south`) should be pasted into the cell as the value for LOCATION.\n\nRun the cell above, and continue running cells individually until you reach step 2."}, {"metadata": {}, "cell_type": "code", "source": "API_KEY = 'xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx'\nPROJECT_ID = 'xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx'\nLOCATION = 'us-south'", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "The first model you will create in this notebook uses the scikit-learn framework. The `sklearn` package is available by default in Watson Studio Python environments, and does not need to be installed."}, {"metadata": {}, "cell_type": "code", "source": "import sklearn\nsklearn.__version__", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "The next cell uses the API key and location variables defined above to authenticate with your Watson Machine Learning service. An error in this cell likely means that you do not have access to a WML service, or that the API key or location provided above is incorrect."}, {"metadata": {}, "cell_type": "code", "source": "from ibm_watson_machine_learning import APIClient\n\nwml_credentials = {\n    \"apikey\": API_KEY,\n    \"url\": 'https://' + LOCATION + '.ml.cloud.ibm.com'\n}\n\nwml_client = APIClient(wml_credentials)", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "# 2. --STOP-- Insert data to code below\n\nPlace your cursor in the empty cell below. Then click the **Find and add data** icon in the upper right corner of the screen. Locate the *modeling_records_2022.csv* file, and use the **Insert to code** dropdown beneath it to insert the data as a pandas DataFrame. Like the `sklearn` package, `pandas` is automatically provided in Watson Studio Python environments.\n\nVerify that the data is imported into the `df_data_1` variable. If it is imported into a different variable, you will need to alter code in some of the cells below to reflect the correct variable.\n\nRun the cell below, and continue running cells individually until you reach step 3."}, {"metadata": {}, "cell_type": "code", "source": "", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "The next cell splits the training data into the feature columns and the label columns, and then splits the data further into a training data set and a testing data set."}, {"metadata": {}, "cell_type": "code", "source": "from sklearn.model_selection import train_test_split\n\nX = df_data_1.drop(['ATTRITION'], axis=1)  # Features\ny = df_data_1['ATTRITION']  # Labels\n\n# Split dataset into training set and test set\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.15) # 85% training and 15% test", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "Next you will tell Watson Machine Learning to use the current project to store the model."}, {"metadata": {}, "cell_type": "code", "source": "wml_client.set.default_project(PROJECT_ID)", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "The following cell provides connection information to the model training data, which will be stored with the model and in FactSheets. You could use the Cloud Object Storage information for this particular project by changing the credentials to match those from above where you inserted the file to code, but for simplicity's sake, you will use a pre-existing file."}, {"metadata": {}, "cell_type": "code", "source": "training_data_references = [\n                {\n                    \"id\": \"attrition\",\n                    \"type\": \"s3\",\n                    \"connection\": {\n                        \"access_key_id\": \"yqcPbWZ0AQPHleHVerrR4Wx5e9pymBdMgydbEra5zCif\",\n                        \"endpoint_url\": \"https://s3.us.cloud-object-storage.appdomain.cloud\",\n                        \"resource_instance_id\": \"crn:v1:bluemix:public:cloud-object-storage:global:a/7d8b3c34272c0980d973d3e40be9e9d2:2883ef10-23f1-4592-8582-2f2ef4973639::\"\n                    },\n                    \"location\": {\n                        \"bucket\": \"faststartlab-donotdelete-pr-nhfd4jnhlxgpc7\",\n                        \"path\": \"modeling_records_2022.csv\"\n                    }\n                }\n            ]", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "The cell below will initialize IBM FactSheet monitoring for this model, and authenticate with the FactSheet service using credentials you have already supplied. Note that Python notebooks in Watson Studio have full support for `pip install`, which allows you to add whatever libraries you need to the notebook environment."}, {"metadata": {}, "cell_type": "code", "source": "try:\n    from ibm_aigov_facts_client import AIGovFactsClient\nexcept:\n    !pip install -U ibm-aigov-facts-client\n    from ibm_aigov_facts_client import AIGovFactsClient\n        \nPROJECT_UID= os.environ['PROJECT_ID']\nCPD_URL=os.environ['RUNTIME_ENV_APSX_URL'][len('https://api.'):]\nCONTAINER_ID=PROJECT_ID\nCONTAINER_TYPE='project'\nEXPERIMENT_NAME='predictive_attrition'\n\nPROJECT_ACCESS_TOKEN=project.project_context.accessToken.replace('Bearer ','')\n\nfacts_client = AIGovFactsClient(api_key=API_KEY,experiment_name=EXPERIMENT_NAME,container_type=CONTAINER_TYPE,container_id=CONTAINER_ID,set_as_current_experiment=True)", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "The next two cells construct metadata for the model, which will be saved with the model itself, and will appear on its FactSheet. If you get errors trying to save the model, they will most likely be from the metadata contained in the model props, specifically the `TYPE` and `SOFTWARE_SPEC_UID`, which frequently change as Watson Studio adds support for new versions of Python, and removes support for outdated versions."}, {"metadata": {}, "cell_type": "code", "source": "fields=X_train.columns.tolist()\nmetadata_dict = {'target_col' : 'ATTRITION', 'fields':fields}", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "software_spec_uid = wml_client.software_specifications.get_id_by_name(\"runtime-22.1-py3.9\")\nprint(\"Software Specification ID: {}\".format(software_spec_uid))\nmodel_props = {\n    wml_client._models.ConfigurationMetaNames.NAME:\"{}\".format(\"attrition challenger - sklearn\"),\n    wml_client._models.ConfigurationMetaNames.TYPE: \"scikit-learn_1.0\",\n    wml_client._models.ConfigurationMetaNames.SOFTWARE_SPEC_UID: software_spec_uid,\n    wml_client._models.ConfigurationMetaNames.TRAINING_DATA_REFERENCES: training_data_references,\n    wml_client._models.ConfigurationMetaNames.LABEL_FIELD: \"ATTRITION\",\n    wml_client._models.ConfigurationMetaNames.CUSTOM: metadata_dict\n}\n\nfacts_client.export_facts.prepare_model_meta(wml_client=wml_client,meta_props=model_props)", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "The next three cells fit the data using a random forest classifier, run predictions on the test data, and then print out the accuracy for how the model did on the test data. Finally, the notebook calculates and displays feature importance."}, {"metadata": {}, "cell_type": "code", "source": "from sklearn.ensemble import RandomForestClassifier\n\n#Create a Gaussian Classifier\nclf = RandomForestClassifier(n_estimators=100)\n\n#Train the model using the training sets y_pred=clf.predict(X_test)\nclf.fit(X_train,y_train)\n\ny_pred = clf.predict(X_test)", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "from sklearn import metrics\n# Model Accuracy, how often is the classifier correct?\nprint(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "feature_imp = pd.Series(clf.feature_importances_,index=X.columns).sort_values(ascending=False)\nfeature_imp", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "The next three cells export data to the FactSheet. The first lists experiments tracked by FactSheets. The second writes some custom data, in this case the URL and other info for this notebook. Note that any data can be written to the FactSheet that might be helpful for model validators."}, {"metadata": {}, "cell_type": "code", "source": "facts_client.runs.list_runs_by_experiment('1')", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "nb_name = \"attrition model creation and deployment\"\nnb_asset_id = \"tbd\"\nnb_asset_url = \"https://\" + CPD_URL + \"/analytics/notebooks/v2/\" + nb_asset_id + \"?projectid=\" + PROJECT_UID + \"&context=cpdaas\"\n\nlatestRunId = facts_client.runs.list_runs_by_experiment('1').sort_values('start_time').iloc[-1]['run_id']\nfacts_client.runs.set_tags(latestRunId, {\"Notebook name\": nb_name, \"Notebook id\": nb_asset_id, \"Notebook URL\" : nb_asset_url})\nfacts_client.export_facts.export_payload(latestRunId)", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "RUN_ID=facts_client.runs.get_current_run_id()\nfacts_client.export_facts.export_payload(RUN_ID)", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "Finally, the model is stored to the project with all of the metadata defined above."}, {"metadata": {}, "cell_type": "code", "source": "print(\"Storing model...\")\npublished_model_details = wml_client.repository.store_model(\n    model=clf, \n    meta_props=model_props,\n    training_target=['ATTRITION'],\n    training_data=X)\nmodel_uid = wml_client.repository.get_model_id(published_model_details)\n\nprint(\"Done\")\nprint(\"Model ID: {}\".format(model_uid))", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "Next, the notebook will use Apache Spark to create a second model. Because you specified a Spark environment when you created this notebook, the `pyspark` runtime will be available without needing to be installed via `pip`."}, {"metadata": {}, "cell_type": "code", "source": "try:\n    from pyspark.sql import SparkSession\nexcept:\n    print('Error: Spark runtime is missing. If you are using Watson Studio change the notebook runtime to Spark.')\n    raise\nspark.version", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "# 3. --STOP-- Insert data to code below\n\nPlace your cursor in the empty cell below. Then click the **Find and add data** icon in the upper right corner of the screen. Locate the *modeling_records_2022.csv* file, and use the **Insert to code** dropdown beneath it to insert the data as a SparkSession DataFrame.\n\nVerify that the data is imported into the `df_data_2` variable. If it is imported into a different variable, you will need to alter code in some of the cells below to reflect the correct variable.\n\nThe remainder of the notebook is very similar to the training of the sklearn model. It will enable FactSheets for the second model, train a Spark Gradient Boost Classifier, and then save that model to the project. You may run the rest of the notebook to its conclusion."}, {"metadata": {}, "cell_type": "code", "source": "", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "Similar to the `sklearn` model, you need to specify metadata for the spark model."}, {"metadata": {}, "cell_type": "code", "source": "software_spec_uid = wml_client.software_specifications.get_id_by_name(\"spark-mllib_3.2\")\nprint(\"Software Specification ID: {}\".format(software_spec_uid))\nmodel_props = {\n    wml_client._models.ConfigurationMetaNames.NAME:\"{}\".format(\"attrition challenger - spark\"),\n    wml_client._models.ConfigurationMetaNames.TYPE: \"mllib_3.2\",\n    wml_client._models.ConfigurationMetaNames.SOFTWARE_SPEC_UID: software_spec_uid,\n    wml_client._models.ConfigurationMetaNames.TRAINING_DATA_REFERENCES: training_data_references,\n    wml_client._models.ConfigurationMetaNames.LABEL_FIELD: \"ATTRITION\"\n}\n\nfacts_client.export_facts.prepare_model_meta(wml_client=wml_client,meta_props=model_props)", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "from pyspark.ml.feature import VectorAssembler\nfrom pyspark.ml.classification import GBTClassifier\nfrom pyspark.ml.evaluation import BinaryClassificationEvaluator\nfrom pyspark.ml import Pipeline, Model", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "from pyspark.sql.types import FloatType\nfor field in fields:\n    df_data_2=df_data_2.withColumn(field,df_data_2[field].cast(\"float\").alias(field))\ndf_data_2=df_data_2.withColumn('ATTRITION',df_data_2['ATTRITION'].cast(\"int\").alias('ATTRITTION'))\ndf_data_2.take(5)", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "va = VectorAssembler(inputCols = fields, outputCol='features')\nva_df = va.transform(df_data_2)\nva_df = va_df.select(['features', 'ATTRITION'])\nva_df.show(3)", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "gbtc = GBTClassifier(labelCol=\"ATTRITION\", maxIter=20)\n\npipeline = Pipeline(stages=[va, gbtc])", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "split_data = df_data_2.randomSplit([0.8, 0.2], 24)\ntrain_data = split_data[0]\ntest_data = split_data[1]\n\nprint(\"Number of training records: \" + str(train_data.count()))\nprint(\"Number of testing records : \" + str(test_data.count()))", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "spark_model = pipeline.fit(train_data)\n\npred = spark_model.transform(test_data)\npred.show(3) ", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "evaluator = BinaryClassificationEvaluator()\nevaluator.setLabelCol(\"ATTRITION\")\nprint(\"Test Area Under ROC: \" + str(evaluator.evaluate(pred, {evaluator.metricName: \"areaUnderROC\"})))", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "print(\"Storing spark model...\")\npublished_model_details = wml_client.repository.store_model(\n    model=spark_model, \n    meta_props=model_props,\n    training_target=['ATTRITION'],\n    training_data=train_data,\n    pipeline=pipeline\n)\nmodel_uid = wml_client.repository.get_model_id(published_model_details)\n\nprint(\"Done\")\nprint(\"Model ID: {}\".format(model_uid))", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "# Congratulations!\n\nYou have completed this notebook. You can now return to the [Data and AI Live Demos lab page](https://cp4d-outcomes.techzone.ibm.com/data-fabric-lab/trusted-ai) and continue with the lab."}], "metadata": {"kernelspec": {"name": "python39", "display_name": "Python 3.9 with Spark", "language": "python3"}, "language_info": {"name": "python", "version": "3.9.7", "mimetype": "text/x-python", "codemirror_mode": {"name": "ipython", "version": 3}, "pygments_lexer": "ipython3", "nbconvert_exporter": "python", "file_extension": ".py"}}, "nbformat": 4, "nbformat_minor": 1}