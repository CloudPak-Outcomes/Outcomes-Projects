{"cells":[{"attachments":{},"cell_type":"markdown","metadata":{"collapsed":true},"source":["# Cloud Pak for Data as a Service services management\n","\n","### Make sure to set the API_key variable in the next cell before executing it\n","\n","This notebook covers:\n","- Get a partial list of the services in the catalog\n","- List the services (resources) in the account\n","- Create a service\n","- Adding a service to the current project\n","- Removing the service from the project\n","- Deleting the service\n","\n","References:\n","- [Watson Data API](https://cloud.ibm.com/apidocs/watson-data-api)\n","- [Resource Controller API](https://cloud.ibm.com/apidocs/resource-controller/resource-controller)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import requests\n","import json\n","import warnings\n","import os, sys\n","from datetime import datetime\n","import inspect\n","\n","import zipfile\n","from io import BytesIO\n","\n","API_key = \"<Insert API key here>\" # from cloud.ibm.com...\n","\n","# Should not use verify=False but I don't want to deal with SSL\n","verify=False\n","warnings.filterwarnings(\"ignore\") # one of \"error\", \"ignore\", \"always\", \"default\", \"module\", or \"once\""]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Support functions\n","instructions:\n","- Select the next empty cell as the current cell\n","- From the code snipet '</>' tab on the right, use `Read data`, `Select data from project`\n","- Then click on `Data asset`, and finally on `cpdalllibs.zip`\n","- Make sure the \"Load as\" selection is set to `StreamingBody object`, and click on `Insert code to cell`\n","- Make sure the inserted code references 'streaming_body_1' in a line like:\n","\n","`      streaming_body_1 = cos_client.get_object(Bucket=bucket, Key=object_key)['Body']`"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Load the python support functions\n","!rm -rf cpdalllibs\n","myzip = zipfile.ZipFile(BytesIO(streaming_body_1.read()))\n","\n","myzip.extractall('.')\n","\n","sys.path.append(\".\")\n","from cpdalllibs.cpdaaslibfns import *\n","importcpdaas()\n","\n","# Test if we have access\n","help(getUsers)\n","print(\"\\nShow the source of a function:\\n\")\n","print(inspect.getsource(getRoles))"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Get an access token"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["resp = getToken(API_key)\n","if resp.status_code > 200 :\n","    print(\"getToken status code: {}, reason: {}\".format(resp.status_code,resp.reason))\n","resp_json = resp.json()\n","access_token = resp_json['access_token']\n","print(\"Got a token at {} GMT\".format(datetime.now().time().isoformat(\"seconds\")))\n","\n","# Header to use in subsequent queries\n","headersAPI = {\n","        'accept': 'application/json',\n","        'Content-type': 'application/json',\n","        'Authorization': 'Bearer ' + access_token,\n","        'cache-control': 'no-cache'\n","}\n","# Get the detail to extract the account_id\n","resp = apikeyDetails(API_key, access_token)\n","if resp.status_code > 200 :\n","    print(\"apikeyDetails status code: {}, reason: {}\".format(resp.status_code,resp.reason))\n","key_details_json = resp.json()\n","\n","account_id = key_details_json['account_id']\n","iam_id = key_details_json['iam_id']"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Get a partial list of the services in the catalog\n","To get a list of all services, we could use a library but since we're not going deep into the catalog entries,it does not save us any work. Here is how we can do the same as above using the library:\n","```\n","!pip install --upgrade ibm-platform-services >/dev/null 2>&1\n","from ibm_platform_services import global_catalog_v1 \n","from ibm_cloud_sdk_core.authenticators.no_auth_authenticator import NoAuthAuthenticator\n","\n","service = global_catalog_v1.GlobalCatalogV1(authenticator=NoAuthAuthenticator() )\n","resp = service.list_catalog_entries(limit=50, q=\"tag:watson kind:service\")\n","res = resp.get_result()\n","print(\"Number of entries: {}\\n\".format(resp_json['count']))\n","print(\"{:<30}  {:<35}   {}\".format(\"Display Name\", \"Entry Name\",\"ID\"))\n","print(\"\\n\".join([\"{:<30}: {:<35} | {}\".format(entry['overview_ui']['en']['display_name'],entry['name'],entry['id']) \n","                     for entry in res['resources']]) )\n","```\n","We can get a maximum of 200 entries for each call. If we expect more, we need to loop using the offset parameter. Using the library, the code would be:\n","```\n","offset = 0\n","limit = 200 # max available limit\n","looping = True\n","print(\"{:<30}  {:<35}   {}\".format(\"Display Name\", \"Entry Name\",\"ID\"))\n","while looping :\n","    resp = service.list_catalog_entries(offset=offset,limit=limit, q=\"tag:watson kind:service\")\n","    res = resp.get_result()\n","    offset = offset + limit\n","    print(\"\\n\".join([\"{:<30}: {:<35} | {}\".format(entry['overview_ui']['en']['display_name'],entry['name'],entry['id']) \n","                     for entry in res['resources']]) )\n","    if (offset > res['count']):\n","        looping = False\n","```"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["resp = listGlobalCatalog(headersAPI, 200)\n","if resp.status_code > 202 :\n","    print(\"Status code: {}, reason: {}\\n\".format(resp.status_code,resp.reason))\n","else :\n","    resp_json = resp.json()\n","    resources_json = [item for item in resp_json['resources'] ]\n","    found_names = [item['name'] for item in resources_json]\n","\n","    print(\"Number of entries: {}\".format(len(resources_json)))\n","    print(\"{:<30}  {:<35}   {}\".format(\"Display Name\", \"Entry Name\",\"ID\"))\n","    print(\"\\n\".join([\"{:<30} | {:<35} | {}\".format(entry['overview_ui']['en']['display_name'],entry['name'],entry['id']) \n","                         for entry in resources_json]) )"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### List one complete entry"]},{"cell_type":"code","execution_count":null,"metadata":{"scrolled":true},"outputs":[],"source":["#list one entry: Machine Learning\n","entry = [entry for entry in resp_json['resources'] if entry['name'] == \"text-to-speech\"][0]\n","print(json.dumps(entry, indent=2, sort_keys=True))"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## List the services (resources) in the account"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# List resources (services) in the account\n","instances_json = getServiceInstances(headersAPI)\n","print(\"Number of instances: {}\".format(len(instances_json['resources'])))\n","# print(json.dumps(instances_json, indent=2, sort_keys=False))\n","print(\"{:<24} | {}\".format(\"Service name\", \"guid\"))\n","print(\"\\n\".join(sorted(([\"{:<24} | {}\".format(item['name'], item['guid']) for item in instances_json['resources']])) ))"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Create a service"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### Display a summary of the available plans"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# we have the resources_json global variable created previously.\n","\n","# We need to find the info on the \"service\". Get the entry from resources_json\n","resource = [item for item in resources_json if item['name'] == 'text-to-speech'][0]\n","# Get the resource id so we can retrieve the child entries\n","resource_id = resource['id']\n","print(\"{}: {}\\n\".format(resource['name'],resource_id))\n","\n","# Get the information the service and pick the resource_plan_id: GET /{id}/{kind}\n","# We call al kinds but in this case, we could limit ourselves to 'plan' since openscale only has plans\n","resp = requests.get(GLOBAL_CATALOG_ENDPOINT + '/{}/{}?include=metadata'.format(resource_id,'*'), headers=headersAPI)\n","if resp.status_code > 202 : # if error\n","    print(\"Status code: {}, reason: {}\\n\".format(resp.status_code,resp.reason))\n","    print(json.dumps(resp_json, indent=2, sort_keys=True))\n","else :\n","    resource_json = resp.json()\n","    print(\"{:<36} | {:<12} | {}\".format(\"Plan id\", \"Plan name\", \"Available geos\"))\n","    print(\"\\n\".join([\"{} | {:<12} | {}\".format(item['id'], item['name'],\",\".join(item['geo_tags'])) \n","                 for item in resource_json['resources'] if item['kind'] == \"plan\"]))"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### Get available resource groups\n","There is at least the \"default\" group"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# List the resources groups\n","resp = requests.get(RESOURCE_ENDPOINT + '/v2/resource_groups', headers=headersAPI)\n","if resp.status_code > 202 : # if error\n","    print(\"Status code: {}, reason: {}\\n\".format(resp.status_code,resp.reason))\n","else :\n","    resources_groups_json = resp.json()\n","    # print(json.dumps(resources_groups_json, indent=2, sort_keys=True))\n","    group_names = [item['name'] for item in resources_groups_json['resources']]\n","    print(\"\\n\".join(group_names))"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### Create the service"]},{"cell_type":"code","execution_count":null,"metadata":{"scrolled":true},"outputs":[],"source":["# Extract the plan ID we want from the aiopenscale resources (see the display summary cell above)\n","plan_id = [item['id'] for item in resource_json['resources'] if item['name'] == 'lite'][0]\n","# Same for the resource group\n","resource_group = [item['id'] for item in resources_groups_json['resources'] if item['name'] == 'default'][0]\n","\n","payload = {\n","    'name': \"text to speech az\", # What we want to name our service\n","    'target': \"us-south\", # One value from the available geos\n","    'resource_group': resource_group, # Resource group ID for Outcomes Project Management\n","    'resource_plan_id': plan_id, # Standard\n","    'tags': ['demo', 'temp']\n","}\n","\n","resp = requests.post(RESOURCE_ENDPOINT + '/v2/resource_instances', json=payload, headers=headersAPI)\n","if resp.status_code > 202 : # if error\n","    print(\"Status code: {}, reason: {}\\n\".format(resp.status_code,resp.reason))\n","else :\n","    print(\"{} created:\".format(payload['name']))\n","T2S_svc = resp.json()\n","print(json.dumps(T2S_svc, indent=2, sort_keys=True))"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Adding a service to the current project"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["WATSON_DATA_ENDPOINT=\"https://api.dataplatform.cloud.ibm.com\"\n","# We need the current compute as to not lose associated services like WML\n","resp = getProject(headersAPI, os.environ[\"PROJECT_ID\"])\n","prj_json=resp.json()\n","compute = prj_json['entity']['compute']\n","compute.append({\n","    # type allowable values: [analytics_engine,spark,machine_learning,streaming_analytics,watson,data_replication]\n","    'type': \"analytics_engine\", # From doc \n","    'guid': T2S_svc['guid'],\n","    'name': T2S_svc['name'],\n","    'credentials': {},\n","    'crn': T2S_svc['crn'] # optional\n","})\n","payload = {\n","    'compute': compute\n","}\n","resp = requests.patch(WATSON_DATA_ENDPOINT + '/v2/projects/{}'.format(os.environ['PROJECT_ID']), \n","                      json=payload, headers=headersAPI)\n","if resp.status_code > 204 : # if error\n","    print(\"Status code: {}, reason: {}\\n\".format(resp.status_code,resp.reason))"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Listing the project services"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["resp = getProject(headersAPI, os.environ[\"PROJECT_ID\"])\n","print(\"Status code: {}, reason: {}\\n\".format(resp.status_code,resp.reason))\n","prj_json=resp.json()\n","print(\"\\n\".join([\"{} - {}\".format(item['type'], item['name']) for item in prj_json['entity']['compute']]))"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Removing the language translator service\n","- Remove the service from the project\n","- Delete the service IDs and the service\n","- Delete the service"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### Remove the service from the project\n","Removing is like adding a list minus the elements we remove"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["resp = getProject(headersAPI, os.environ[\"PROJECT_ID\"])\n","prj_json=resp.json()\n","compute = [item for item in prj_json['entity']['compute'] if item['name'] != \"text to speech az\"]\n","\n","payload = {\n","    'compute': compute\n","}\n","resp = requests.patch(WATSON_DATA_ENDPOINT + '/v2/projects/{}'.format(os.environ['PROJECT_ID']), \n","                      json=payload, headers=headersAPI)\n","if resp.status_code > 204 : # if error\n","    print(\"Status code: {}, reason: {}\\n\".format(resp.status_code,resp.reason))"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Prove that the service is gone from the project\n","resp = getProject(headersAPI, os.environ[\"PROJECT_ID\"])\n","prj_json=resp.json()\n","print(\"\\n\".join([\"{} - {}\".format(item['type'], item['name']) for item in prj_json['entity']['compute']]))"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### Delete the service"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["resp = requests.delete(RESOURCE_ENDPOINT + '/v2/resource_instances/{}?recursive=true'.format(T2S_svc[\"guid\"]), headers=headersAPI)\n","if resp.status_code > 204 :\n","    print(\"Status code: {}, reason: {}\\n\".format(resp.status_code,resp.reason))\n","else :\n","    print(\"'{}' deleted\".format(T2S_svc['name']))"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### Author\n","**Jacques Roy** is a member of the IBM Enablement for Data and AI\n","\n","Copyright © 2023. This notebook and its source code are released under the terms of the MIT License."]}],"metadata":{"kernelspec":{"display_name":"Python 3.10","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.9"}},"nbformat":4,"nbformat_minor":1}
