{"cells":[{"attachments":{},"cell_type":"markdown","metadata":{"collapsed":true},"source":["# Accident data exploration and cleansing\n","\n","## On CPDaaS: Make sure to first insert a \"project token\"\n","Click on the three vertical dots icon in the uper right of the screen, then click on `Insert project token`\n","\n","**Once inserted, execute the cell**.\n","\n","A project token is only available if you followed the prerequesite instructions to create on in your project."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import warnings\n","import pandas as pd\n","import numpy as np\n","import math\n","import time\n","import os\n","from ibm_watson_studio_lib import access_project_or_space\n","\n","import matplotlib.pyplot as plt\n","# matplotlib.patches lets us create colored patches, which we can use for legends in plots\n","import matplotlib.patches as mpatches\n","%matplotlib inline\n","\n","# Get access to the prohject API for CPD on-premises\n","if \"USER_ID\" in os.environ :\n","    wslib = access_project_or_space()"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Get the Chicago data \n","If you already got the dataset in a previous notebook execution, you can get the final dataset from the project in a later cell.\n","\n","For more information on finding and accessing open datasets, see:\n","- Youtube Byte-Size Data Science: \n","  - <a href=\"https://youtu.be/D46A9r3bfjM\" target=\"_blank\">019-Finding Data: Socrata Catalog (youtube video)</a>\n","  - <a href=\"https://youtu.be/4C9ShcU--ek\" target=\"_blank\">020-Socrata Datasets (youtube video)</a>\n","- Companion notebooks: \n","  - <a href=\"https://github.com/jacquesroy/byte-size-data-science/blob/master/Notebooks/019-SocrataDataCatalog.ipynb\" target=\"_blank\">019-SocrataDataCatalog.ipynb</a>\n","  - <a href=\"https://github.com/jacquesroy/byte-size-data-science/blob/master/Notebooks/020-SocrataDataAccess-Spark.ipynb\" target=\"_blank\">020-SocrataDataAccess-Spark.ipynb</a>\n","  \n","You can also find information on the dataset used in this notebook at:\n","<a href=\"https://data.cityofchicago.org/Transportation/Traffic-Crashes-Crashes/85ca-t3if\" target=\"_blank\">Chicago Traffic Crashes - Crashes</a>"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Library used to read datasets\n","# https://github.com/xmunoz/sodapy\n","!pip install sodapy 2>&1 >pipsodapy.txt\n","\n","from sodapy import Socrata"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### Get a connection to the city of Chicago public data\n","See: \n","- https://pypi.org/project/sodapy/\n","- https://dev.socrata.com/\n","\n","The Socrata Open Data API allows you to programmatically access a wealth of open data resources from governments, non-profits, and NGOs around the world."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Unauthenticated client only works with public data sets. Note 'None'\n","# in place of application token, and no username or password:\n","client = Socrata(\"data.cityofchicago.org\", None)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### Retrieve the six months before May 15, 2023\n","Six months of data is sufficient to get a good idea of the state of accidents in Chicago.<br/>\n","This notebook uses upto May 15 to make it consistent from execution to execution."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from datetime import date\n","from dateutil.relativedelta import relativedelta\n","\n","# If we wanted to do today:\n","# six_months = (date.today() - relativedelta(months=+6)).strftime('%Y-%m-%d')\n","# We are using a fix date for future comparisons\n","six_months = (date(2023,5,15) - relativedelta(months=+6)).strftime('%Y-%m-%d')\n","where = \"crash_date > '{}'\".format(six_months)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### Note:\n","If the next cell execution fails, try again."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# The request may timeout. If so, retry it.\n","# The looping is required since the API returns at most 10000 records per call.\n","crashes_df = pd.DataFrame(client.get(\"85ca-t3if\", where=where, limit=10000))\n","offset = 10000\n","result = client.get(\"85ca-t3if\", where=where, offset=offset, limit=10000)\n","while (len(result) > 0) :\n","    # crashes_df = crashes_df.append(pd.DataFrame(result), sort=True)\n","    crashes_df = pd.concat([crashes_df, pd.DataFrame(result)], ignore_index=True)\n","    offset += 10000\n","    result = client.get(\"85ca-t3if\", where=where, offset=offset, limit=10000)\n","\n","print(\"Number of records: {}, number of columns: {}\".format(crashes_df.shape[0], crashes_df.shape[1]))"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Explore the dataset\n","You already know from the previous cell that there are 52842 records with 49 columns.\n","\n","Try the following:\n","- `DataFrame.head`: display the first few records\n","- `DataFrame.dtypes`: provides the type of each column\n","- `DataFrame.count`: Count number of non-NA/null observations.\n","- `DataFrame.max`: Maximum of the values in the object.\n","- `DataFrame.min`: Minimum of the values in the object.\n","- `DataFrame.nunique`: Count number of distinct elements in specified axis.\n","- `DataFrame.groupby`: Group records by values in a specific column.\n","\n","See also Byte-Size Data Science:\n","- <a href=\"https://youtu.be/AeeHapnLhyE\">018-Python Pandas Data Exploration (youtube video)</a>\n","- <a href=\"https://github.com/jacquesroy/byte-size-data-science/blob/master/Notebooks/018-PandasInsightsIntoTheChicagoAccident.ipynb\" target=\"_blank\">018-PandasInsightsIntoTheChicagoAccident.ipynb</a>"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Display a few records"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Look at the types of each column"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Convert a few columns\n","# Convert the two datetime columns to the proper type and the speed limit\n","crashes_df['crash_date'] = \\\n","           crashes_df['crash_date'].apply(pd.to_datetime, infer_datetime_format=True, errors='coerce')\n","crashes_df['date_police_notified'] = \\\n","           crashes_df['date_police_notified'].apply(pd.to_datetime, infer_datetime_format=True, errors='coerce')\n","crashes_df['posted_speed_limit'] = crashes_df['posted_speed_limit'].astype(int)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# How many non-null values in each column?\n","# If the count is low, the column is likely useless"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Look at the smallest values in each column\n","# Keep in mind that most columns are treated as strings. \n","# A conversion to a proper type would be more appropriate"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Look at the largest values in each column"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Look at the number of unique values for columns: \n","# posted_speed_limit, traffic_control_device, weather_condition, and roadway_surface_cond\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# How many of each unique value in 'posted_speed_limit' ?"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# How many of each unique value in 'traffic_control_device' ?"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### Exploration conclusion\n","There is a lot more that can be done in data exploration depending on how much of the information \n","provided by the records you want to use.\n","\n","- **Look at the data**: This gives a basic idea of what is in there.\n","- **Look at the types in the Pandas dataframe**: Reading from Socrata returns \"object\"s!\n","- **Convert some columns**: After more analysis, it is better to convert the columns to their appropriate types.\n","This can provide better values in other statistics.\n","- **Doing a count of non-null values**: tells us that some columns include too few values to be useful\n","- **Looking at min/max values**: Shows the range of values in each column.<br/>\n","For example, seeing a minimum speed limit of 0 seems suspicious. \n","- **Number of unique values in a column**: Can identify or justify if a column contains categorical values\n","- **Number of each categorical values**: How balanced are the values?<br/>\n","The `traffic_control_device` column has 28729 values set to \"NO CONTROLS\". That's over 50% of the values!<br/>\n","Seeing all the categorical values can show issues. The `posted_speed_limit` column includes: 0, 1, 2, 3, 5, 8, 9, 23...<br/>\n","What should be done with those? Aggregate to the closest \"standard\" value? Ignore them?\n","\n","This lab uses the `latitude` and `longitude` and adds `injuries_fatal` and `injuries_total`. The exploration shows that some rows do not include `latitude` and `longitude` (479 records). They must be removed."]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Get only accidents with longitude/latitude\n","- Remove records without latitude and longitude\n","- Use only a few columns\n","- Convert them to their proper types"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Has to be a better way to do this...\n","# Select a few columns\n","crashes_df = crashes_df[['injuries_fatal','injuries_total','latitude','longitude']]\n","\n","# convert 'injuries_fatal' and 'injuries_total' to float otherwide, int causes problems.\n","crashes_df = crashes_df.astype({'injuries_fatal': float, 'injuries_total': float,\n","                                'latitude': float, 'longitude': float})\n","\n","crashes_df = crashes_df.dropna() # Remove missing values\n","\n","# make sure it includes only rows with non-zero longitude and latitude\n","crashes_df = crashes_df[crashes_df['longitude'] != 0]\n","crashes_df = crashes_df[crashes_df['latitude'] != 0]\n","\n","print(\"Number of crashes: {}\".format(crashes_df.shape[0]))"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### Save the data to the project\n","This way we can avoid re-reading the data from the Chicago site"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["crashes_df.to_csv(\"ChicagoCrashes.csv\", index=False)\n","res = wslib.upload_file('ChicagoCrashes.csv')\n","print(\"File {} uploaded\".format(res['name']))"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Read the data from the project\n","If you are returning, you can simply read the local file instead of going back to Chicago"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["body = wslib.load_data(\"ChicagoCrashes.csv\")\n","crashes_df = pd.read_csv(body)\n","crashes_df.head()"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Continue here after getting the final crashes_df\n","How can you know if the data has a decent distribution?\n","\n","Latitude and longitude provide location information. This is not the same as X and Y coordinates \n","but considering the relatively small area covered by the Chicago area, you can treat them as \n","equivalent.\n","\n","You can get a good idea of the distribution through a scatter plot.\n","\n","For more information on spatial data, look at Byte-Size Data Science:\n","- <a href=\"https://youtu.be/A0rjUgDGo88\" target=\"_blank\">044-Spatial Data: Introduction</a>\n","- <a href=\"https://youtu.be/LKANJBxxtuQ\" target=\"_blank\">045-Geo Distances</a>"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### Divide dataset into accident categories: fatal, non-fatal but with injuries, none of the above\n","This will give us a better idea of the overall accident picture"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["killed_df = crashes_df[crashes_df['injuries_fatal']>0]\n","injured_df = crashes_df[np.logical_and(crashes_df['injuries_total']>0, crashes_df['injuries_fatal']==0)]\n","# killed_or_injured_df = killed_df.append(injured_df)\n","killed_or_injured_df = pd.concat([killed_df, injured_df], ignore_index=True)\n","nothing_df = crashes_df[np.logical_and(crashes_df['injuries_fatal']==0, crashes_df['injuries_total']==0)]\n","\n","print(\"Number of records: {}\".format(crashes_df.shape[0]))\n","print(\"Number of fatal accidents: {}\".format(killed_df.shape[0]))\n","print(\"Number of injury accidents: {}\".format(injured_df.shape[0]))\n","print(\"Number of no-injury accidents: {}\".format(nothing_df.shape[0]))\n","\n","crashes_df.describe()"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Scatterplot\n","Create a visualization of the accidents. **Note that this is not a map !**\n","\n","Having a graphical representation of our data can give us some insights on how to proceed."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Use calculated values for the plot limits (border)\n","minlong = crashes_df['longitude'].min(axis=0) - 0.005\n","maxlong = crashes_df['longitude'].max(axis=0) + 0.005\n","minlat = crashes_df['latitude'].min(axis=0) - 0.005\n","maxlat = crashes_df['latitude'].max(axis=0) + 0.005\n","print(\"min, max, longitude, latitude: {}, {}, {}, {}\".format(minlong,maxlong,minlat,maxlat))"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["nb_rows = 1\n","nb_plots = 2\n","\n","fig, axes = plt.subplots(nrows=nb_rows, ncols=2)\n","fig.set_figheight(6)\n","fig.set_figwidth(18)\n","\n","axes[0].scatter(crashes_df.longitude, crashes_df.latitude, color='darkseagreen', alpha=0.05, s=2)\n","axes[0].title.set_text('Motor Vehicle Accidents in Chicago (last six months)')\n","axes[0].set_xlabel('Longitude', labelpad = 5)\n","axes[0].set_ylabel('latitude', labelpad = 5)\n","\n","axes[1].scatter(nothing_df.longitude, nothing_df.latitude, color='blue', alpha=0.04, s=2)\n","axes[1].scatter(injured_df.longitude, injured_df.latitude, color='yellow', alpha=0.12, s=2)\n","axes[1].scatter(killed_df.longitude, killed_df.latitude, color='red', alpha=1, s=2)\n","\n","#create legend\n","blue_patch = mpatches.Patch( label='car body damage', color='blue')\n","yellow_patch = mpatches.Patch(color='yellow', label='personal injury')\n","red_patch = mpatches.Patch(color='red', label='lethal accidents')\n","axes[1].legend([blue_patch, yellow_patch, red_patch],('car body damage', 'personal injury', 'fatal accidents'), \n","           loc='upper left', prop={'size':10})\n","axes[1].title.set_text('Severity of Motor Vehicle Collisions in Chicago')\n","axes[1].set_xlabel('Longitude', labelpad = 5)\n","axes[1].set_ylabel('latitude', labelpad = 5)\n","plt.show()"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Conclusion\n","You can see that the accidents are well distributed to the point that the scaater plot\n","almost simulate a map of the chicago streets. The resulting data is what you need to move forward.\n","\n","So much more exploration could have been done. This notebook gives a good feel of what should be done \n","with data before using it."]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### Author\n","**Jacques Roy** is a member of the IBM Enablement for Data and AI\n","\n","Copyright Â© 2023. This notebook and its source code are released under the terms of the MIT License."]}],"metadata":{"kernelspec":{"display_name":"Python 3.10","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.9"}},"nbformat":4,"nbformat_minor":1}
