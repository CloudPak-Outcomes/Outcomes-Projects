{"cells":[{"attachments":{},"cell_type":"markdown","metadata":{"collapsed":true},"source":["# Model evaluation\n","In this notebook we test the models on data that was not used in the model creation.\n","\n","## CPDaaS: Make sure to first insert a \"project token\"\n","Click on the three vertical dots icon in the uper right of the screen, then click on Insert project token\n","\n","Once inserted, execute the cell.\n","\n","A project token is only available if you followed the prerequesite instructions to create on in your project.\n","\n","## WML python library\n","The `ibm-watson-machine-learning` library is already part of the runtime environment, so it does not need to be installed with the command:\n","\n","`!pip install ibm-watson-machine-learning`\n","\n","At the time of this writing, the library supports Cloud Pak for Data as a Service as well as Cloudpak for Data versions 3.5, 4.0, 4.5, and 4.6.\n","\n","### For more information on the Python libraries see:\n","- <a href=\"https://www.ibm.com/docs/en/cloud-paks/cp-data/4.6.x?topic=lib-watson-studio-python\" target=\"_blank\">ibm-watson-studio-lib for Python</a>\n","- <a href=\"https://ibm-wml-api-pyclient.mybluemix.net/?_ga=2.103887936.1953236104.1685457836-762907244.1683830523&_gl=1*6plrrn*_ga*NzYyOTA3MjQ0LjE2ODM4MzA1MjM.*_ga_FYECCCS21D*MTY4NTQ1NzgzNi4yNi4xLjE2ODU0NjA1MzkuMC4wLjA.\" target=\"_blank\">The ibm-watson-machine-learning library</a>"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Get a WML connection\n","- Replace the value of `cpd_url` with the proper cloud region or the proper cluster URL\n","- Set the value of `API_key` to your API key"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# cluster URL, make sure it ends with \"/\", and no \"zen\" ending\n","#cpd_url = \"https://cpd-cpd.ai-governance-12345a678e90addd123c4567c8f9a012-3456.us-east.containers.appdomain.cloud/\"\n","cpd_url = \"https://us-south.ml.cloud.ibm.com\"\n","API_key = \"<YOUR_API_KEY>\" # either CPD or CPDaaS\n"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### Create a Watson Machine Learning (WML) client connection"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import os\n","import json\n","import pandas as pd\n","from sklearn.metrics import mean_squared_error\n","from ibm_watson_studio_lib import access_project_or_space\n","\n","from ibm_watson_machine_learning import APIClient\n","\n","if \"USER_ID\" in os.environ :\n","    wslib = access_project_or_space()\n","    wml_credentials = {\n","                   \"url\": cpd_url,\n","                   \"username\": \"<USERNAME>\",\n","                   \"apikey\" : API_key,\n","                   \"instance_id\": \"openshift\",\n","                   \"version\" : \"4.0\"\n","                  }\n","else :\n","    wml_credentials = {\n","                   \"url\": cpd_url,\n","                   \"apikey\": API_key\n","                  }\n","\n","client = APIClient(wml_credentials)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Listing projects models\n","Also get the model details"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Need to set either the space id (deployment) or the project id\n","# for the next few cells, we need to set it to the project ID\n","## space_details = client.spaces.get_details()\n","## space_uid = client.spaces.get_id(space_details[\"resources\"][0]) # deployment space\n","## client.set.default_space(space_uid)\n","client.set.default_project(os.environ[\"PROJECT_ID\"])"]},{"cell_type":"code","execution_count":null,"metadata":{"scrolled":true},"outputs":[],"source":["models_details = client.repository.get_model_details()\n","print(\"\\n\".join([item['metadata']['name'] for item in models_details['resources']]))"]},{"cell_type":"code","execution_count":null,"metadata":{"scrolled":true},"outputs":[],"source":["models_pd = client.repository.list_models()\n","AutoAI_id = models_pd.loc[models_pd['NAME'].str.startswith(\"AutoAI\")][[\"ID\"]].reset_index().loc[0]['ID']\n","SPSS_id = models_pd.loc[models_pd['NAME'].str.startswith(\"SPSS\")][[\"ID\"]].reset_index().loc[0]['ID']\n","print(\"AutoAI id: {}\\nSPSS id: {}\".format(AutoAI_id,SPSS_id))"]},{"cell_type":"code","execution_count":null,"metadata":{"scrolled":true},"outputs":[],"source":["# Another way to get the model IDs\n","wml_models = wslib.assets.list_assets(\"wml_model\")\n","print(\"\\n\".join([\"{:26} : {}\".format(item['name'], item['asset_id']) for item in wml_models]))"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## AutoAI model details\n","There are a lot of details attached to a model. Here is a small sample:\n","- Number of rcords involved in the model training\n","- Label column\n","- Feature importance\n","- Input fields schema\n","- Training data reference\n","- Model name\n","- and more"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### List the feature importance\n","List the important features in order of importance. This is something that can be seen \n","through the Watson Studio UI in the AutoAI experiment.\n","\n","The two most important features are `HOTSPOT2` and `PRIM_DRIVER_GENDER`"]},{"cell_type":"code","execution_count":null,"metadata":{"scrolled":true},"outputs":[],"source":["AutoAI_details = [item for item in models_details['resources'] if \"AutoAI\" in item['metadata']['name']][0]\n","importance = AutoAI_details['entity']['metrics'][0]['context']['features_importance'][0]['features']\n","# Use only the entries greater than zero\n","importance = {k:v for (k,v) in importance.items() if v > 0.0 }\n","importance = dict(sorted(importance.items(), key=lambda item: item[1], reverse=True))\n","importance"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### List the input column names\n","Note that the `RISK` column is not part of the input.\n","\n","The output columns definition is an empty array."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["print(\"Input columns:\")\n","print(\", \".join([item['name'] for item in AutoAI_details['entity']['schemas']['input'][0]['fields']]))"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## SPSS model details\n","The SPSS model includes different information from AutoAI but stilll includes information such as:\n","- Schemas: input, output\n","- Software specifications\n","- Name\n","- and more"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### List input and output column names\n","The output columns include the input columns with the addition of:\n","- `Partition`\n","- `$XR-RISK`\n","- `$XRE-RISK`"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["SPSS_details = [item for item in models_details['resources'] if \"SPSS\" in item['metadata']['name']][0]\n","print(\"Input columns:\")\n","print(\", \".join([item['name'] for item in SPSS_details['entity']['schemas']['input'][0]['fields']]))\n","print(\"\\nOutput columns:\")\n","print(\", \".join([item['name'] for item in SPSS_details['entity']['schemas']['output'][0]['fields']]))"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Load data to score\n","This data was not seen during model creation. It contains over 20 thousand records.\n","\n","This section uses the first 20 records of the dataset."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["body = wslib.load_data(\"ValidationRecords.csv\")\n","records_df = pd.read_csv(body)\n","print(\"Number of available records: {}\".format(records_df.shape[0]))\n","# scoring_records = records_df.sample(frac = 0.001) would be 20-21 records\n","scoring_records_df = records_df[:20]\n","records_df.head()"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### Some statistics on the records\n","This should really be done on the training data but since we have 20000 records, that should be good enough."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["print(\"Min risk: {}, max risk: {}, range: {}\".format(records_df['RISK'].min(), \n","                                                     records_df['RISK'].max(),\n","                                                    records_df['RISK'].max() - records_df['RISK'].min())\n","     )"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Load the AutoAI model and score some records\n","The AutoAI model can run in the notebook runtime. There is no need to first deploy it.\n","This makes it quite simple to use in a notebook."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["AutoAI_model = client.repository.load(AutoAI_id)\n","AutoAI_results = AutoAI_model.predict(scoring_records_df.drop(columns=['RISK']).to_numpy())"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### Compare results\n","Values, differences and percentage of differences"]},{"cell_type":"code","execution_count":null,"metadata":{"scrolled":false},"outputs":[],"source":["percent = 100 * (scoring_records_df[\"RISK\"] - AutoAI_results) / scoring_records_df[\"RISK\"]\n","diff = scoring_records_df[\"RISK\"] - AutoAI_results\n","d = {'risk': scoring_records_df[\"RISK\"], 'AutoAI': AutoAI_results,\n","     \"diff\": diff, \"percent\": percent}\n","df = pd.DataFrame(data=d)\n","df.head(20)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### Root mean squared error (RMSE)\n","Applied only on the small set of records scored. \n","This can varie greatly from the value returned in the AutoAI experiment on the training data.\n","\n","The RISK value in the validation records range from 4 to 59. \n","A RMSE of 5 would represent roughly a 9% error."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["mean_squared_error(scoring_records_df[\"RISK\"], AutoAI_results)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Deploy the SPSS model and score some records\n","In this case, the load command would create a local file with the model in it and returns the path to the model.\n","\n","The SPSS model depends on a runtime that is not part of the notebook. It must use the Watson Machine Learning(WML) for execution.\n","\n","We need a deployment space!"]},{"cell_type":"code","execution_count":null,"metadata":{"scrolled":true},"outputs":[],"source":["spaces_list = client.spaces.list()\n","spaces_list.head()"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### Promote the model to the deployment space\n","From the project to the deployment space.\n","This deployment space must be associated with a Watson Machine Learning (WML) service"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# This assumes the desired deployment space is at index 0. If not, please change the index.\n","space_id = spaces_list.iloc[0]['ID']\n","SPSS_details = [item for item in models_details['resources'] if \"SPSS\" in item['metadata']['name']][0]\n","client.set.default_space(space_id)\n","promoted_asset_id = client.spaces.promote(SPSS_id, source_project_id=os.environ['PROJECT_ID'], \n","                                          target_space_id=space_id)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### Deploy the newly promoted model\n","Note: online_url is deprecated and will be removed in a future release. Use serving_urls instead."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["deployment = client.deployments.create(\n","    artifact_uid=promoted_asset_id,\n","    meta_props={\n","        client.deployments.ConfigurationMetaNames.NAME: \"SPSS risk factor deployment\",\n","        client.deployments.ConfigurationMetaNames.ONLINE:{}}\n",")\n","deployment_id = client.deployments.get_id(deployment)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### Score the records\n","Notice the fields names are extracted from the model details and the scoring records are directly from the dataframe.\n","There must not be invalid values so they are replaces with zeros (`fillna(0)`)"]},{"cell_type":"code","execution_count":null,"metadata":{"scrolled":true},"outputs":[],"source":["scoring_data = {\n","    client.deployments.ScoringMetaNames.INPUT_DATA: [{\n","        \"fields\": [item['name'] for item in SPSS_details['entity']['schemas']['input'][0]['fields']],\n","        \"values\": scoring_records_df.fillna(0).to_numpy()\n","    }]\n","}\n","predictions = client.deployments.score(deployment_id, scoring_data)\n","print(predictions)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### Compare results\n","Values, differences and percentage of differences"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Extract the values for column \"$XR-RISK\" at position: -2\n","SPSS_results = [item[-2] for item in predictions['predictions'][0]['values']]"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["percent = 100 * (scoring_records_df[\"RISK\"] - SPSS_results) / scoring_records_df[\"RISK\"]\n","diff = scoring_records_df[\"RISK\"] - SPSS_results\n","d = {'risk': scoring_records_df[\"RISK\"], 'SPSS': SPSS_results,\n","     \"diff\": diff, \"percent\": percent}\n","df = pd.DataFrame(data=d)\n","df.head(20)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### Root mean squared error (RMSE)\n","Applied only on the small set of records scored. \n","This can varie greatly based on the results used, only 20 values here."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["mean_squared_error(scoring_records_df[\"RISK\"], SPSS_results)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Cleanup\n","- Remove the deployment\n","- Remove the promoted asset"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["client.deployments.delete(deployment_id)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["client.data_assets.delete(promoted_asset_id)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### Author\n","**Jacques Roy** is a member of the IBM Enablement for Data and AI\n","\n","Copyright © 2023. This notebook and its source code are released under the terms of the MIT License."]}],"metadata":{"kernelspec":{"display_name":"Python 3.10","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.9"}},"nbformat":4,"nbformat_minor":1}
