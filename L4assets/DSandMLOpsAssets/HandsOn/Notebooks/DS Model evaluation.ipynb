{"cells": [{"metadata": {"collapsed": true}, "cell_type": "markdown", "source": "# Model evaluation\nIn this notebook we test the models on data that was not used in the model creation.\n\n## CPDaaS: Make sure to first insert a \"project token\"\nClick on the three vertical dots icon in the uper right of the screen, then click on Insert project token\n\nOnce inserted, execute the cell.\n\nA project token is only available if you followed the prerequesite instructions to create on in your project.\n\n## WML python library\nThe `ibm-watson-machine-learning` library is already part of the runtime environment, so it does not need to be installed with the command:\n\n`!pip install ibm-watson-machine-learning`\n\nAt the time of this writing, the library supports Cloud Pak for Data as a Service as well as Cloudpak for Data versions 3.5, 4.0, 4.5, and 4.6.\n\n### For more information on the Python libraries see:\n- <a href=\"https://www.ibm.com/docs/en/cloud-paks/cp-data/4.6.x?topic=lib-watson-studio-python\" target=\"_blank\">ibm-watson-studio-lib for Python</a>\n- <a href=\"https://ibm-wml-api-pyclient.mybluemix.net/?_ga=2.103887936.1953236104.1685457836-762907244.1683830523&_gl=1*6plrrn*_ga*NzYyOTA3MjQ0LjE2ODM4MzA1MjM.*_ga_FYECCCS21D*MTY4NTQ1NzgzNi4yNi4xLjE2ODU0NjA1MzkuMC4wLjA.\" target=\"_blank\">The ibm-watson-machine-learning library</a>"}, {"metadata": {}, "cell_type": "markdown", "source": "## Get a WML connection\n- Replace the value of `cpd_url` with the proper cloud region or the proper cluster URL\n- Set the value of `API_key` to your API key"}, {"metadata": {}, "cell_type": "code", "source": "# cluster URL, make sure it ends with \"/\", and no \"zen\" ending\n#cpd_url = \"https://cpd-cpd.ai-governance-12345a678e90addd123c4567c8f9a012-3456.us-east.containers.appdomain.cloud/\"\ncpd_url = \"https://us-south.ml.cloud.ibm.com\"\nAPI_key = \"<YOUR_API_KEY>\" # either CPD or CPDaaS\n\njroy_key = \"Nl863Ics2aPukbm0BGz5KprpF943Tssjp_ycQVJ1jhDV\" # from jacquesr cloud.ibm.com account\nTZoutcomes_API_key = \"8ILStV-WrapOVckMn5wdnM7EkOVU5qaA1ZGS0g86E_PW\" # with manager priv\nAPI_key = jroy_key\ncpd_url=\"https://us-south.ml.cloud.ibm.com\"", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "### Create a Watson Machine Learning (WML) client connection"}, {"metadata": {}, "cell_type": "code", "source": "import os\nimport json\nimport pandas as pd\nfrom sklearn.metrics import mean_squared_error\nfrom ibm_watson_studio_lib import access_project_or_space\n\nfrom ibm_watson_machine_learning import APIClient\n\nif \"USER_ID\" in os.environ :\n    wslib = access_project_or_space()\n    wml_credentials = {\n                   \"url\": cpd_url,\n                   \"username\": \"<USERNAME>\",\n                   \"apikey\" : API_key,\n                   \"instance_id\": \"openshift\",\n                   \"version\" : \"4.0\"\n                  }\nelse :\n    wml_credentials = {\n                   \"url\": cpd_url,\n                   \"apikey\": API_key\n                  }\n\nclient = APIClient(wml_credentials)", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "## Listing projects models\nAlso get the model details"}, {"metadata": {}, "cell_type": "code", "source": "# Need to set either the space id (deployment) or the project id\n# for the next few cells, we need to set it to the project ID\n## space_details = client.spaces.get_details()\n## space_uid = client.spaces.get_id(space_details[\"resources\"][0]) # deployment space\n## client.set.default_space(space_uid)\nclient.set.default_project(os.environ[\"PROJECT_ID\"])", "execution_count": null, "outputs": []}, {"metadata": {"scrolled": true}, "cell_type": "code", "source": "models_details = client.repository.get_model_details()\nprint(\"\\n\".join([item['metadata']['name'] for item in models_details['resources']]))", "execution_count": null, "outputs": []}, {"metadata": {"scrolled": true}, "cell_type": "code", "source": "models_pd = client.repository.list_models()\nAutoAI_id = models_pd.loc[models_pd['NAME'].str.startswith(\"AutoAI\")][[\"ID\"]].reset_index().loc[0]['ID']\nSPSS_id = models_pd.loc[models_pd['NAME'].str.startswith(\"SPSS\")][[\"ID\"]].reset_index().loc[0]['ID']\nprint(\"AutoAI id: {}\\nSPSS id: {}\".format(AutoAI_id,SPSS_id))", "execution_count": null, "outputs": []}, {"metadata": {"scrolled": true}, "cell_type": "code", "source": "# Another way to get the model IDs\nwml_models = wslib.assets.list_assets(\"wml_model\")\nprint(\"\\n\".join([\"{:26} : {}\".format(item['name'], item['asset_id']) for item in wml_models]))", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "## AutoAI model details\nThere are a lot of details attached to a model. Here is a small sample:\n- Number of rcords involved in the model training\n- Label column\n- Feature importance\n- Input fields schema\n- Training data reference\n- Model name\n- and more"}, {"metadata": {}, "cell_type": "markdown", "source": "### List the feature importance\nList the important features in order of importance. This is something that can be seen \nthrough the Watson Studio UI in the AutoAI experiment.\n\nThe two most important features are `HOTSPOT2` and `PRIM_DRIVER_GENDER`"}, {"metadata": {"scrolled": true}, "cell_type": "code", "source": "AutoAI_details = [item for item in models_details['resources'] if \"AutoAI\" in item['metadata']['name']][0]\nimportance = AutoAI_details['entity']['metrics'][0]['context']['features_importance'][0]['features']\n# Use only the entries greater than zero\nimportance = {k:v for (k,v) in importance.items() if v > 0.0 }\nimportance = dict(sorted(importance.items(), key=lambda item: item[1], reverse=True))\nimportance", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "### List the input column names\nNote that the `RISK` column is not part of the input.\n\nThe output columns definition is an empty array."}, {"metadata": {}, "cell_type": "code", "source": "print(\"Input columns:\")\nprint(\", \".join([item['name'] for item in AutoAI_details['entity']['schemas']['input'][0]['fields']]))", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "## SPSS model details\nThe SPSS model includes different information from AutoAI but stilll includes information such as:\n- Schemas: input, output\n- Software specifications\n- Name\n- and more"}, {"metadata": {}, "cell_type": "markdown", "source": "### List input and output column names\nThe output columns include the input columns with the addition of:\n- `Partition`\n- `$XR-RISK`\n- `$XRE-RISK`"}, {"metadata": {}, "cell_type": "code", "source": "SPSS_details = [item for item in models_details['resources'] if \"SPSS\" in item['metadata']['name']][0]\nprint(\"Input columns:\")\nprint(\", \".join([item['name'] for item in SPSS_details['entity']['schemas']['input'][0]['fields']]))\nprint(\"\\nOutput columns:\")\nprint(\", \".join([item['name'] for item in SPSS_details['entity']['schemas']['output'][0]['fields']]))", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "## Load data to score\nThis data was not seen during model creation. It contains over 20 thousand records.\n\nThis section uses the first 20 records of the dataset."}, {"metadata": {}, "cell_type": "code", "source": "body = wslib.load_data(\"ValidationRecords.csv\")\nrecords_df = pd.read_csv(body)\nprint(\"Number of available records: {}\".format(records_df.shape[0]))\n# scoring_records = records_df.sample(frac = 0.001) would be 20-21 records\nscoring_records_df = records_df[:20]\nrecords_df.head()", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "### Some statistics on the records\nThis should really be done on the training data but since we have 20000 records, that should be good enough."}, {"metadata": {}, "cell_type": "code", "source": "print(\"Min risk: {}, max risk: {}, range: {}\".format(records_df['RISK'].min(), \n                                                     records_df['RISK'].max(),\n                                                    records_df['RISK'].max() - records_df['RISK'].min())\n     )", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "## Load the AutoAI model and score some records\nThe AutoAI model can run in the notebook runtime. There is no need to first deploy it.\nThis makes it quite simple to use in a notebook."}, {"metadata": {}, "cell_type": "code", "source": "AutoAI_model = client.repository.load(AutoAI_id)\nAutoAI_results = AutoAI_model.predict(scoring_records_df.drop(columns=['RISK']).to_numpy())", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "### Compare results\nValues, differences and percentage of differences"}, {"metadata": {"scrolled": false}, "cell_type": "code", "source": "percent = 100 * (scoring_records_df[\"RISK\"] - AutoAI_results) / scoring_records_df[\"RISK\"]\ndiff = scoring_records_df[\"RISK\"] - AutoAI_results\nd = {'risk': scoring_records_df[\"RISK\"], 'AutoAI': AutoAI_results,\n     \"diff\": diff, \"percent\": percent}\ndf = pd.DataFrame(data=d)\ndf.head(20)", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "### Root mean squared error (RMSE)\nApplied only on the small set of records scored. \nThis can varie greatly from the value returned in the AutoAI experiment on the training data.\n\nThe RISK value in the validation records range from 4 to 59. \nA RMSE of 5 would represent roughly a 9% error."}, {"metadata": {}, "cell_type": "code", "source": "mean_squared_error(scoring_records_df[\"RISK\"], AutoAI_results)", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "## Deploy the SPSS model and score some records\nIn this case, the load command would create a local file with the model in it and returns the path to the model.\n\nThe SPSS model depends on a runtime that is not part of the notebook. It must use the Watson Machine Learning(WML) for execution.\n\nWe need a deployment space!"}, {"metadata": {"scrolled": true}, "cell_type": "code", "source": "spaces_list = client.spaces.list()\nspaces_list.head()", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "### Promote the model to the deployment space\nFrom the project to the deployment space.\nThis deployment space must be associated with a Watson Machine Learning (WML) service"}, {"metadata": {}, "cell_type": "code", "source": "# This assumes the desired deployment space is at index 0. If not, please change the index.\nspace_id = spaces_list.iloc[0]['ID']\nSPSS_details = [item for item in models_details['resources'] if \"SPSS\" in item['metadata']['name']][0]\nclient.set.default_space(space_id)\npromoted_asset_id = client.spaces.promote(SPSS_id, source_project_id=os.environ['PROJECT_ID'], \n                                          target_space_id=space_id)", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "### Deploy the newly promoted model\nNote: online_url is deprecated and will be removed in a future release. Use serving_urls instead."}, {"metadata": {}, "cell_type": "code", "source": "deployment = client.deployments.create(\n    artifact_uid=promoted_asset_id,\n    meta_props={\n        client.deployments.ConfigurationMetaNames.NAME: \"SPSS risk factor deployment\",\n        client.deployments.ConfigurationMetaNames.ONLINE:{}}\n)\ndeployment_id = client.deployments.get_id(deployment)", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "### Score the records\nNotice the fields names are extracted from the model details and the scoring records are directly from the dataframe.\nThere must not be invalid values so they are replaces with zeros (`fillna(0)`)"}, {"metadata": {"scrolled": true}, "cell_type": "code", "source": "scoring_data = {\n    client.deployments.ScoringMetaNames.INPUT_DATA: [{\n        \"fields\": [item['name'] for item in SPSS_details['entity']['schemas']['input'][0]['fields']],\n        \"values\": scoring_records_df.fillna(0).to_numpy()\n    }]\n}\npredictions = client.deployments.score(deployment_id, scoring_data)\nprint(predictions)", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "### Compare results\nValues, differences and percentage of differences"}, {"metadata": {}, "cell_type": "code", "source": "# Extract the values for column \"$XR-RISK\" at position: -2\nSPSS_results = [item[-2] for item in predictions['predictions'][0]['values']]", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "percent = 100 * (scoring_records_df[\"RISK\"] - SPSS_results) / scoring_records_df[\"RISK\"]\ndiff = scoring_records_df[\"RISK\"] - SPSS_results\nd = {'risk': scoring_records_df[\"RISK\"], 'SPSS': SPSS_results,\n     \"diff\": diff, \"percent\": percent}\ndf = pd.DataFrame(data=d)\ndf.head(20)", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "### Root mean squared error (RMSE)\nApplied only on the small set of records scored. \nThis can varie greatly based on the results used, only 20 values here."}, {"metadata": {}, "cell_type": "code", "source": "mean_squared_error(scoring_records_df[\"RISK\"], SPSS_results)", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "## Cleanup\n- Remove the deployment\n- Remove the promoted asset"}, {"metadata": {}, "cell_type": "code", "source": "client.deployments.delete(deployment_id)", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "client.data_assets.delete(promoted_asset_id)", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "### Author\n**Jacques Roy** is a member of the IBM Enablement for Data and AI\n\nCopyright \u00a9 2023. This notebook and its source code are released under the terms of the MIT License."}], "metadata": {"kernelspec": {"name": "python3", "display_name": "Python 3.10", "language": "python"}, "language_info": {"name": "python", "version": "3.10.9", "mimetype": "text/x-python", "codemirror_mode": {"name": "ipython", "version": 3}, "pygments_lexer": "ipython3", "nbconvert_exporter": "python", "file_extension": ".py"}}, "nbformat": 4, "nbformat_minor": 1}