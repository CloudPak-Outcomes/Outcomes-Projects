{"cells": [{"metadata": {"collapsed": true}, "cell_type": "markdown", "source": "# Splitting modeling records\n\n## CPDaaS: Make sure to first insert a \"project token\"\nClick on the three vertical dots icon in the uper right of the screen, then click on `Insert project token`\n\n**Once inserted, execute the cell**.\n\nA project token is only available if you followed the prerequesite instructions to create on in your project."}, {"metadata": {}, "cell_type": "markdown", "source": "## Get the modeling data"}, {"metadata": {}, "cell_type": "code", "source": "import pandas as pd\nimport os\nfrom ibm_watson_studio_lib import access_project_or_space\n\n# Get access to the prohject API for CPD on-premises\nif \"USER_ID\" in os.environ :\n    wslib = access_project_or_space()\n\n\nbody = wslib.load_data(\"ModelingRecords.csv\")\nrecords_df = pd.read_csv(body)", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "## Split the records randomly 80/20\nIn some cases you would want to split 60/20/20 for training, testing, and validation.<br/>\nWhen using SPSS modeler or AutoAI, the training/testing split is done during the processing.<br/>\nFor this reason, we simply want some validation records that were'nt use in training or testing for later work."}, {"metadata": {}, "cell_type": "code", "source": "valid_pd = records_df.sample(frac = 0.2)\ntraining_pd = records_df.drop(valid_pd.index)\n\nprint(\"Number of validation records: {}\".format(valid_pd.shape[0]))\nprint(\"Number of training records: {}\".format(training_pd.shape[0]))", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "## Write the dataset to the project"}, {"metadata": {}, "cell_type": "code", "source": "valid_pd.to_csv(\"ValidationRecords.csv\", index=False)\nres = wslib.upload_file('ValidationRecords.csv')\nprint(\"File {} uploaded\".format(res['name']))", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "training_pd.to_csv(\"TrainingRecords.csv\", index=False)\nres = wslib.upload_file('TrainingRecords.csv')\nprint(\"File {} uploaded\".format(res['name']))", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "### Author\n**Jacques Roy** is a member of the IBM Enablement for Data and AI\n\nCopyright \u00a9 2023. This notebook and its source code are released under the terms of the MIT License."}], "metadata": {"kernelspec": {"name": "python3", "display_name": "Python 3.10", "language": "python"}, "language_info": {"name": "python", "version": "3.10.9", "mimetype": "text/x-python", "codemirror_mode": {"name": "ipython", "version": 3}, "pygments_lexer": "ipython3", "nbconvert_exporter": "python", "file_extension": ".py"}}, "nbformat": 4, "nbformat_minor": 1}