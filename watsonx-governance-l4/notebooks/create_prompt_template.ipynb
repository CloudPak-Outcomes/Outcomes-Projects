{
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat_minor": 4,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "markdown",
   "source": "# Create an Azure OpenAI Generative AI Model as a prompt template in watsonx.governance 2.x",
   "metadata": {
    "id": "1431ce28-77ce-443e-9b13-1ca914e8f40d"
   }
  },
  {
   "cell_type": "markdown",
   "source": "This notebook has been adapted for the watsonx.governance Level 4 PoX hands-on lab. It is originally based on [this notebook](https://github.com/rreno85/wxgovlab/blob/main/watsonxgov%20detached%20prompt%20-%20Azure%20OpenAI.ipynb) by Bob Reno.\n\nThis notebook will create a *detached* prompt template asset that references a generative AI model in Azure OpenAI to start governing this model in **watsonx.governance**.\n\n**Notes**\n\n- This notebook should be run using with Runtime 22.2 & Python 3.10 or greater runtime environment (e.g.: 3.11, 3.12), if you are viewing this in Watson Studio, and do not see \"Python 3.10/3.11\" in the upper right corner of your screen, please update the runtime now. \n- This notebook assumes you have **access to an Azure OpenAI account that has the `opeanai-gpt-3.5` model deployed**. If you don't have access to this account, try reserving the `Access to Azure OpenAI GPT 3.5 Model` environment available in IBM's [TechZone](https://techzone.ibm.com/) (as of September 2024).\n- If users wish to execute this notebook for task types other than summarization, please consult [this](https://github.com/IBM/watson-openscale-samples/blob/main/IBM%20Cloud/WML/notebooks/watsonx/README.md) document for guidance on evaluating prompt templates for the available task types.\n",
   "metadata": {
    "id": "6fc80eab-cd96-42e6-999d-dbe5b864b28b"
   }
  },
  {
   "cell_type": "markdown",
   "source": "## Setup <a name=\"settingup\"></a>\n\nRun the below cell to install the required packages.",
   "metadata": {
    "id": "11000d0d-a3da-463b-97b9-1f766cdac8bd"
   }
  },
  {
   "cell_type": "code",
   "source": "!pip install --upgrade datasets==2.10.0 --no-cache | tail -n 1\n!pip install --upgrade evaluate --no-cache | tail -n 1\n!pip install --upgrade --extra-index-url https://test.pypi.org/simple/ ibm-aigov-facts-client | tail -n 1\n!pip install --upgrade \"ibm-watson-openscale>=3.0.4\" | tail -n 1\n!pip install \"ibm-watson-machine-learning\"\n!pip install --upgrade matplotlib | tail -n 1\n!pip install --upgrade pydantic==1.10.11 --no-cache | tail -n 1\n!pip install --upgrade sacrebleu --no-cache | tail -n 1\n!pip install --upgrade sacremoses --no-cache | tail -n 1\n!pip install --upgrade textstat --no-cache | tail -n 1\n!pip install --upgrade openai rich azure-identity --no-cache | tail -n 1\n# !pip install --upgrade transformers --no-cache | tail -n 1",
   "metadata": {
    "id": "f66daba2-fdbd-4d2f-89ae-0dead6f60bd1"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": "**Note:** you may need to *restart the kernel* to use the updated packages. You don't need to run the cell above again after restarting",
   "metadata": {
    "id": "5068ca17-4f03-42ed-a0fc-596e9a99eb10"
   }
  },
  {
   "metadata": {
    "id": "65a267dd-1a2b-4bc1-a8f9-ffe2c35c681d"
   },
   "cell_type": "markdown",
   "source": "Fill-in your platform and Azure credentials:"
  },
  {
   "metadata": {
    "id": "65793428-ef4e-4299-9e22-49b4f75d8033"
   },
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import os\n",
    "from rich import print\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "CPD_URL = \"https://cpd-cpd.apps.________________.ocp.techzone.ibm.com/\"\n",
    "CPD_USERNAME = \"complianceofficer\"\n",
    "CPD_API_KEY = \"<EDIT THIS>\"\n",
    "\n",
    "AZURE_OPENAI_ENDPOINT = \"<EDIT THIS>\"\n",
    "AZURE_OPENAI_DEPLOYMENT_NAME = \"<EDIT THIS>\"\n",
    "AZURE_CLIENT_ID = \"<EDIT THIS>\"\n",
    "AZURE_CLIENT_SECRET = \"<EDIT THIS>\"\n",
    "AZURE_TENANT_ID = \"<EDIT THIS>\"\n",
    "\n",
    "PROJECT_ID = os.environ.get('PROJECT_ID', \"<YOUR_PROJECT_ID>\")\n",
    "print(f\"Your project id is '{PROJECT_ID}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "source": "### Function to create the access token",
   "metadata": {
    "id": "eca538bc-4bc9-4866-b0fe-68b6483ddd48"
   }
  },
  {
   "cell_type": "markdown",
   "source": "This function generates an IAM access token using the provided credentials. The API calls for creating and scoring prompt template assets utilize the token generated by this function.",
   "metadata": {
    "id": "a89c703a-8f85-4e0f-9aed-a6d806620d83"
   }
  },
  {
   "cell_type": "code",
   "source": "import requests\nimport urllib3, json  # noqa: E401\nurllib3.disable_warnings()\n\ndef generate_access_token():\n    headers={}\n    headers[\"Content-Type\"] = \"application/json\"\n    headers[\"Accept\"] = \"application/json\"\n    data = {\n        \"username\":CPD_USERNAME,\n        \"api_key\":CPD_API_KEY\n    }\n    data = json.dumps(data).encode(\"utf-8\")\n    url = CPD_URL + \"/icp4d-api/v1/authorize\"\n    response = requests.post(url=url, data=data, headers=headers,verify=False)\n    response.raise_for_status()\n    json_data = response.json()\n    iam_access_token = json_data['token']\n    print(\"Access token generated succesfully!\")\n    return iam_access_token\n\niam_access_token = generate_access_token()",
   "metadata": {
    "id": "b002ae27-7cc7-456b-ab9c-a29417f68d06"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": "## Creating the Prompt Template\n\nThe following cell shows the development of a prompt template used to summarize resumes from job applicants. \n\nWe will test inference on Azure OpenAI and create a detached prompt template in our project in watsonx that references the model and prompt.",
   "metadata": {
    "id": "149f387e-9850-4f12-816c-247cc6ac0c83"
   }
  },
  {
   "cell_type": "code",
   "source": "PROMPT_TEMPLATE = \"\"\"\nYou will be given a resume. Please summarize the resume in 100 words or less.\n\n--- start of text ---\n{text}\n--- end of text ---\n\"\"\".strip()",
   "metadata": {
    "id": "40b2226e-e08a-4fb5-8c9f-a5cf1dfb6e54"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": "import pandas as pd\nimport asyncio\nfrom openai import AsyncAzureOpenAI\nfrom azure.identity import ClientSecretCredential, get_bearer_token_provider\n\ndef get_azure_token_provider():\n    default_scope = \"https://cognitiveservices.azure.com/.default\"\n    credential = ClientSecretCredential(\n        tenant_id=os.environ.get('AZURE_TENANT_ID', AZURE_TENANT_ID),\n        client_id=os.environ.get('AZURE_CLIENT_ID' ,AZURE_CLIENT_ID),\n        client_secret=os.environ.get('AZURE_CLIENT_SECRET', AZURE_CLIENT_SECRET)\n    )\n    return get_bearer_token_provider(credential, default_scope)\n\nasync def summarize_resume(text:str, max_tokens:int=200, token_provider=None):\n    \"\"\"\n    This function uses the Azure OpenAI API to summarize the text of the resume given.\n    Usage: `summary = await summarize('[resume text to summarize]')`\n    \"\"\"\n    if token_provider is None:\n        token_provider = get_azure_token_provider()\n    client = AsyncAzureOpenAI(\n        azure_endpoint=os.environ.get('AZURE_OPENAI_ENDPOINT', AZURE_OPENAI_ENDPOINT),\n        api_version=\"2024-02-15-preview\",\n        azure_ad_token_provider=token_provider\n    )\n    model_response = await client.chat.completions.create(\n        model=os.environ.get('AZURE_OPENAI_DEPLOYMENT_NAME', AZURE_OPENAI_DEPLOYMENT_NAME),\n        messages=[{\"role\": \"user\", \"content\": PROMPT_TEMPLATE.format(text=text)}],\n        max_tokens=max_tokens\n    )\n    return model_response.choices[0].message.content\n\nasync def summarize_batch(resumes:list) -> list:\n    \"\"\"Summarize all the resumes given\"\"\"\n    token_provider = get_azure_token_provider()\n    summaries = await asyncio.gather(\n        *[summarize_resume(resume, token_provider=token_provider) for resume in resumes]\n    )\n    return summaries",
   "metadata": {
    "id": "6c23f098-f2e8-458e-844d-2b7f75fa1bdd"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": "### Load the resume data",
   "metadata": {
    "id": "1860982c-2663-428f-9006-3edfa024d0f1"
   }
  },
  {
   "cell_type": "code",
   "source": "data = pd.read_csv(\"https://raw.githubusercontent.com/CloudPak-Outcomes/Outcomes-Projects/main/watsonx-governance-l4/data/resume_summarization_test_data.csv\").head(10)\nprint(f\"{len(data)} rows of data loaded\")\ndata.head()",
   "metadata": {
    "id": "900fd715db90482a8543af0682407871"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": "### Generate the summaries of the resumes\n\n**Note:** This might take a while to finish running",
   "metadata": {
    "id": "77a74110bed64404870ece9ad2957381"
   }
  },
  {
   "cell_type": "code",
   "source": "data['generated_text'] = await summarize_batch(data['Resume'].values)\ndata.head()",
   "metadata": {
    "id": "67f5ec1f4ae2496a8851fe027fb1540c"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": "Display the results",
   "metadata": {
    "id": "859fa2ff3bdc44129149499380f8c8ea"
   }
  },
  {
   "cell_type": "code",
   "source": "# you can run this multiple times to show the results from different row samples\ndef display_result(row):\n    print(f\"[bold]Resume:[/bold]\\n[red]{row.Resume}[/red]\")\n    print(f\"[bold]AI Generated Summary:[/bold]\\n[blue1]{row.generated_text}[/blue1]\")\n    print(f\"[bold]Reference (Labeled) Summary:[/bold]\\n[green]{row.Summarization}[/green]\")\n\ndisplay_result(data.sample().iloc[0])",
   "metadata": {
    "id": "4b5007fda7544422bdb54282888e3900"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": "### Create the detached prompt template <a name=\"detached_prompt\"></a>",
   "metadata": {
    "id": "de9f4870-e1fb-45da-8dd6-6f8d12399009"
   }
  },
  {
   "cell_type": "markdown",
   "source": "Create a detached prompt template in your project for the summarization task that references the Azure OpenAI model.",
   "metadata": {
    "id": "91b5fddd-d6e7-4834-b780-8c23ea0c065b"
   }
  },
  {
   "cell_type": "code",
   "source": "from ibm_aigov_facts_client import (\n    AIGovFactsClient, CloudPakforDataConfig,\n    DetachedPromptTemplate, PromptTemplate\n)\nfrom ibm_aigov_facts_client.utils.enums import Task\n\ncreds = CloudPakforDataConfig(\n    service_url=CPD_URL,\n    username=CPD_USERNAME,\n    api_key=CPD_API_KEY\n)\nfacts_client = AIGovFactsClient(\n    cloud_pak_for_data_configs=creds,\n    container_id=PROJECT_ID,\n    container_type=\"project\",\n    disable_tracing=True\n)",
   "metadata": {
    "id": "69f88bdc-efb8-4236-bfb1-9a4cdde4bbb0"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": "detached_information = DetachedPromptTemplate(\n    prompt_id=\"detached-aoai-prompt\",\n    model_id=f\"azure/{AZURE_OPENAI_DEPLOYMENT_NAME}\",\n    model_provider=\"Azure OpenAI\",\n    model_name=\"GPT-3.5-turbo\",\n    model_url=AZURE_OPENAI_ENDPOINT,\n    prompt_url=\"prompt_url\",\n    prompt_additional_info={\"model_owner\": \"Microsoft\", \"model_version\": \"gpt-3.5-turbo-1106\"}\n)\nprompt_name = \"Detached prompt for Azure OpenAI GPT-3.5-turbo\"\nprompt_description = \"A detached prompt for summarization using Azure OpenAI's GPT-3.5-turbo model\"\n\n# define parameters for PromptTemplate\nprompt_template = PromptTemplate(\n    input=PROMPT_TEMPLATE,\n    prompt_variables={\"text\": \"\"},\n)\npta_details = facts_client.assets.create_detached_prompt(\n    model_id=f\"azure/{AZURE_OPENAI_DEPLOYMENT_NAME}\",\n    task_id=Task.SUMMARIZATION, # 'summarization' task\n    name=prompt_name,\n    description=prompt_description,\n    prompt_details=prompt_template,\n    detached_information=detached_information\n)\nproject_pta_id = pta_details.to_dict()[\"asset_id\"]\nprint(f\"Detached Prompt template ID: '{project_pta_id}'\")",
   "metadata": {
    "id": "324b7daa-653a-469b-aeb6-b1f0d2c60302"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": "factsheets_url = f\"{CPD_URL.strip('/')}/wx/prompt-details/{project_pta_id}/factsheet?context=wx&project_id={PROJECT_ID}\"\ndisplay(Markdown(f\"[Click here to navigate to the published factsheet in the project]({factsheets_url})\"))",
   "metadata": {
    "id": "dd87f51d-301c-476c-b93b-fc99b805bcaf"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": "**<u>Click the link above to go to the newly published factsheet in your watsonx project</u>**",
   "metadata": {
    "id": "8f39af31-7049-45b6-a2fd-f9d2874cf481"
   }
  }
 ]
}
